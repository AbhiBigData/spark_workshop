<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">

    <title>Apache Spark 2 Workshop - The Core of Spark Core</title>

    <meta name="description" content="Apache Spark 2 Workshop - The Core of Spark Core">
    <meta name="author" content="Jacek Laskowski">

    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/beige.css" id="theme">

    <!-- Code syntax highlighting -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>

    <!-- https://github.com/hakimel/reveal.js/issues/174 -->
    <style>
      .slides .header {
        position: absolute;
        top: 0px;
        right: 0px;
      }
      .slides .footer {
        position: absolute;
        bottom: 0px;
        left: 35%;
      }
    </style>
    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
  </head>

  <body>
    <div class="reveal">

      <div class="slides">
        <div class="footer">
          <small>Copyright ©2017 Jacek Laskowski</small>
        </div>

        <section class="intro" data-transition="zoom">
          <p>
            <img width="25%" style="background:none; border:none; box-shadow:none;" data-src="images/spark-logo.png">
            <img width="15%" src="images/jacek_laskowski_20141201_512px.png" style="border: 0">
          </p>
          <h1>The Core of Spark Core</h1>
          <h4><a href="https://twitter.com/jaceklaskowski">@jaceklaskowski</a> / <a href="http://stackoverflow.com/users/1305344/jacek-laskowski">StackOverflow</a> / <a href="https://github.com/jaceklaskowski">GitHub</a> / <a href="http://bit.ly/mastering-apache-spark">Mastering Apache Spark 2</a></h4>
        </section>

        <section id="sparkconf">
          <h2>SparkConf</h2>
          <ol>
            <li><b>SparkConf</b> represents the configuration of your Spark application</li>
            <li>Switch to Mastering Apache Spark 2
              <ul>
                <li><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-configuration.html">SparkConf — Programmable Configuration for Spark Applications</a></li>
              </ul>
            </li>
          </ol>
        </section>

        <section id="sparkcontext">
          <h2>SparkContext — The Entry Point to Spark Services</h2>
          <ol>
            <li><b>SparkContext</b> is the entry point to the Spark services in your Spark application</li>
            <li>SparkContext manages the connection to a Spark execution environment
              <ul>
                <li>Defined using the <b>master URL</b></li>
              </ul>
            </li>
            <li>Switch to Mastering Apache Spark 2
              <ul>
                <li><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-sparkcontext.html">SparkContext — Entry Point to Spark (Core)</a></li>
              </ul>
            </li>
          </ol>
        </section>

        <section>
          <section id="rdd">
            <h2>RDD</h2>
            <ol>
              <li><b>RDD</b> &mdash; <b>R</b>esilient <b>D</b>istributed <b>D</b>ataset</li>
              <li>Primary data abstraction and the core of Spark Core</li>
              <li>Different RDD types per transformation</li>
              <li>Switch to Mastering Apache Spark 2
                <ul>
                  <li><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd.html">RDD — Resilient Distributed Dataset</a></li>
                </ul>
              </li>
            </ol>
          </section>
          <section id="rdd-traits">
            <h2>RDD Traits</h2>
            <ol>
              <li><b>RDD</b> is an abstract class with 5 properties:
                <ul>
                  <li><b>Dependencies</b> &mdash; parent RDDs</li>
                  <li><b>Partitions</b></li>
                  <li><b>compute</b> function to compute a partition</li>
                  <li><b>Partitioner</b> (optional) &mdash; defines key hashing (hash, range)</li>
                  <li><b>Preferred locations</b> (optional) &mdash; locality info</li>
                </ul>
              </li>
            </ol>
          </section>
          <section id="partitions">
            <h2>Partitions</h2>
            <ol>
              <li>
                <b>Partitions</b> are logical buckets for data.
              </li>
              <li>
                Partitions correspond to Hadoop's splits (if the data lives on HDFS) or partitioning schemes in the source storage
              </li>
              <li>
                RDD (and hence the data inside) is partitioned.
              </li>
              <li>
                Spark manages data using partitions that helps parallelize distributed data processing with minimal network traffic for sending data between executors.
              </li>
              <li>
                Data in partitions can be <b>skewed</b>, i.e. unevenly distributed across partitions.
              </li>
            </ol>
          </section>
          <section>
            <p>
              <img width="100%" src="images/spark-rdd-partitioned-distributed.png" style="border: 0">
            </p>
          </section>
        </section>

        <section id="operators">
          <section>
            <h2>RDD Operators</h2>
            <ol>
              <li><b>Transformation</b> is a lazy RDD operation that creates one or many RDDs</li>
              <li><b>Action</b> is a RDD operation that produces non-RDD Scala values</li>
              <li>Switch to Mastering Apache Spark 2
                <ul>
                  <li><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd-operations.html">Operators - Transformations and Actions</a></li>
                  <li><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd-transformations.html">Transformations</a></li>
                  <li><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd-actions.html">Actions</a></li>
                </ul>
              </li>
            </ol>
          </section>
        </section>

        <section id="caching">
          <h2>RDD Caching and Persistence</h2>
          <ol>
            <li><b>Caching</b> is an optimization technique</li>
            <li>Saves RDDs so they can be reused in subsequent Spark jobs</li>
            <li><b>cache</b> and <b>persist</b> operators with StorageLevels</li>
            <li><b>unpersist</b> operator to clean up</li>
            <li>Switch to Mastering Apache Spark 2
              <ul>
                <li><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd-caching.html">RDD Caching and Persistence</a></li>
                <li><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd-StorageLevel.html">StorageLevel</a></li>
              </ul>
            </li>
          </ol>
        </section>

        <section id="shuffle">
          <h2>Shuffle</h2>
          <ol>
            <li>
              <b>Shuffle</b> is Spark's mechanism for re-distributing data so that it’s grouped differently across partitions.
            </li>
            <li>
              Data is often distributed unevenly across partitions.
            </li>
            <li>
              <b>repartition</b> and <b>coalesce</b> operators can repartition a dataset.
            </li>
            <li>Switch to Mastering Apache Spark 2
              <ul>
                <li><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd-dependencies.html">RDD Dependencies</a></li>
                <li><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-rdd-shuffle.html">RDD Shuffle</a></li>
              </ul>
            </li>
          </ol>
        </section>

        <section id="dagscheduler">
          <section>
            <h2>DAGScheduler</h2>
            <img width="60%" src="images/dagscheduler-rdd-partitions-job-resultstage.png" style="border: 0">
          </section>
          <section>
            <h2>Jobs</h2>
            <img width="70%" src="images/rdd-job-partitions.png" style="border: 0">
          </section>
          <section>
            <h2>Stages</h2>
            <img width="70%" src="images/dagscheduler-stages.png" style="border: 0">
          </section>
        </section>

        <section id="taskscheduler">
          <section>
            <h2>Tasks</h2>
            <img width="100%" src="images/stage-tasks.png" style="border: 0">
          </section>
        </section>

        <section id="questions" style="text-align: left">
          <h1>Questions?</h1>
          <p>
            <ul>
              <li>Read <a href="https://bit.ly/mastering-apache-spark">Mastering Apache Spark 2</a>
                <ul>
                  <li>https://bit.ly/mastering-apache-spark</li>
                </ul>
              </li>
              <li>Follow <a href="https://twitter.com/jaceklaskowski">@jaceklaskowski</a> on twitter</li>
              <li>Upvote <a href="http://stackoverflow.com/users/1305344/jacek-laskowski">my activities on StackOverflow</a></li>
              <li>Use <a href="https://github.com/jaceklaskowski">Jacek's code at GitHub</a></li>
              <li>Read <a href="https://medium.com/@jaceklaskowski">Jacek Laskowski @ Medium</a></li>
              <li>Visit <a href="https://blog.jaceklaskowski.pl">Jacek Laskowski's blog</a></li>
            </ul>
          </p>
        </section>

      </div>
    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>

    <script>

        // Full list of configuration options available at:
        // https://github.com/hakimel/reveal.js#configuration
        Reveal.initialize({
            controls: true,
            progress: true,
            history: true,
            center: true,

            transition: 'slide', // none/fade/slide/convex/concave/zoom

            // Optional reveal.js plugins
            dependencies: [
                { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
                { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                { src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
                { src: 'plugin/zoom-js/zoom.js', async: true },
                { src: 'plugin/notes/notes.js', async: true }
            ]
        });

    </script>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-45999426-3', 'auto');
      ga('send', 'pageview');

    </script>
  </body>
</html>
