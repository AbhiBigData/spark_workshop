<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Apache Spark 2 Workshop &mdash; Multi-Dimensional Aggregation (Spark SQL)</title>

    <meta name="description" content="Apache Spark 2 Workshop &mdash; Multi-Dimensional Aggregation (Spark SQL)">
    <meta name="author" content="Jacek Laskowski">

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/beige.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>

    <!-- https://github.com/hakimel/reveal.js/issues/174 -->
    <style>
      .slides .header {
        position: absolute;
        top: 0px;
        right: 0px;
      }
      .slides .footer {
        position: absolute;
        bottom: 0px;
        left: 35%;
      }
    </style>
  </head>

  <body>
    <div class="reveal">
      <div class="slides">

        <div class="footer">
          <small>Copyright ©2017 Jacek Laskowski</small>
        </div>

        <section class="intro" data-transition="zoom">
          <p>
            <img width="5%" style="background:none; border:none; box-shadow:none;" data-src="images/scala-logo.png">
            <img width="17%" style="background:none; border:none; box-shadow:none;" data-src="images/spark-logo.png">
            <img width="8%" src="images/jacek_laskowski_20141201_512px.png" style="border: 0">
          </p>
          <h1>Multi-Dimensional Aggregation</h1>
          <h4><a href="https://twitter.com/jaceklaskowski">@jaceklaskowski</a> / <a href="http://stackoverflow.com/users/1305344/jacek-laskowski">StackOverflow</a> / <a href="https://github.com/jaceklaskowski">GitHub</a><br />
          Books: <a href="http://bit.ly/mastering-apache-spark">Mastering Apache Spark</a>  / <a href="http://bit.ly/spark-structured-streaming">Spark Structured Streaming</a></h4>
        </section>

        <section id="agenda" data-markdown>
          <script type="text/template">
            ## Agenda

            1. [Multi-dimensional rollup Operator](#/rollup)
              * [Exercise](#/rollup-exercise): Total and average salaries by department and company-wide
            1. [Multi-dimensional cube Operator](#/cube)
            1. [GROUPING SETS SQL clause](#/grouping-sets)
            1. [grouping Aggregate Function](#/grouping)
            1. [grouping_id Aggregate Function](#/grouping-id)
              * [Exercise](#/grouping-id-exercise): Convert grouping_id to bitmask
            1. ["Explaining" Query Plans](#/explain)
          </script>
        </section>

        <section>
          <section id="rollup" data-markdown style="font-size: 0.9em;">
            <script type="text/template">
              ## Multi-dimensional rollup Operator

              1. **rollup** calculates subtotals and totals over (ordered) combination of groups
                ```scala
                val inventory =
                  Seq(("t1", 2015, 100), ("t1", 2016, 50), ("t2", 2016, 40))
                    .toDF("name", "year", "amount")
                inventory.rollup("name", "year").sum("amount")
                ```
                * **Quiz**: How many records in result set?
              1. Advanced variant of **groupBy** with higher efficiency
              1. Creates **RelationalGroupedDataset**
                * Supports untyped, Row-based **agg**
                * Shortcuts for _the usual suspects_, e.g. **avg**, **count**, **pivot**
              1. Switch to Mastering Apache Spark 2
                * [rollup Aggregation Operator](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-sql-multi-dimensional-aggregation.html#rollup)
            </script>
          </section>
          <section id="rollup-exercise" data-markdown>
            <script type="text/template">
              ## Exercise: Total and average salaries by department and company-wide

              1. Develop a standalone Spark SQL application (IntelliJ IDEA)
              1. Use **rollup** aggregate operator (and multi-column **agg**)
              1. Use Spark API scaladoc
                * [Dataset](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset)
                * [RelationalGroupedDataset](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.RelationalGroupedDataset)
              1. Time: **30 mins**
            </script>
          </section>
        </section>

        <section>
          <section id="cube" data-markdown>
            <script type="text/template">
              ## Multi-dimensional cube Operator

              1. **cube** is similar to **rollup** but calculates subtotals and totals over **all combinations** of groups
                ```scala
                val inventory =
                  Seq(("t1", 2015, 100), ("t1", 2016, 50), ("t2", 2016, 40))
                    .toDF("name", "year", "amount")
                inventory.cube("name", "year").sum("amount") // note cube (not rollup)
                ```
                * **Quiz**: How many records in result set?
              1. Advanced variant of **groupBy** with higher efficiency
              1. Creates **RelationalGroupedDataset**
              1. Switch to Mastering Apache Spark 2
                * [cube Aggregation Operator](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-sql-multi-dimensional-aggregation.html#cube)
            </script>
          </section>
        </section>

        <section id="grouping-sets" data-markdown>
          <script type="text/template">
            ## GROUPING SETS SQL clause

            1. Spark SQL supports **GROUPING SETS** in SQL only
            1. Used in GROUP BY allows to specify more than one GROUP BY option in the same record set
              * Equivalent to several GROUP BYs connected by UNION
            ```scala
Seq(("a1", "b1", 3), ("a1", "b2", 7), ("a2", "b2", 5))
  .toDF("a", "b", "c")
  .createOrReplaceTempView("t1")
val q = sql(
  "SELECT a,b, SUM(c) FROM t1 GROUP BY a, b GROUPING SETS (a,b)"
)
            ```
            **Quiz**: How many records in result set?
            1. Switch to Mastering Apache Spark 2
              * [GROUPING SETS SQL Clause](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-sql-multi-dimensional-aggregation.html#grouping-sets)
          </script>
        </section>

        <section id="grouping" data-markdown>
          <script type="text/template">
            ## grouping Aggregate Function

            1. **grouping** - aggregate function that indicates whether a specified column in a GROUP BY list is aggregated or not
              ```scala
workshops
  .cube("city", "year")
  .agg(grouping("city"), grouping("year"))
  .sort($"city".desc_nulls_last, $"year".desc_nulls_last)
              ```
              * returns 1 for aggregated or 0 for not aggregated
            1. Switch to Mastering Apache Spark 2
              * [grouping Aggregate Function](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-sql-functions.html#grouping)
          </script>
        </section>

        <section>
          <section id="grouping-id" data-markdown>
            <script type="text/template">
              ## grouping_id Aggregate Function

              1. **Exercise** (hard): Can you guess yourself?
              1. Switch to Mastering Apache Spark 2
                * [grouping_id Aggregate Function](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-sql-functions.html#grouping_id)
            </script>
          </section>
          <section id="grouping-id-exercise" data-markdown>
            <script type="text/template">
              ## Exercise: Convert grouping_id to bitmask

              1. Find the function to _return the string representation of the binary value of a long column_
              1. Use the function to "binarize" **grouping_id** results
              1. Use Spark API scaladoc
                * [functions object](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$)
              1. Time: **30 mins**
            </script>
          </section>
        </section>

        <section id="explain">
          <h2>"Explaining" Query Plans</h2>
          <ol>
            <li><b>explain</b> is an operator that shows the logical and physical plans
              <ul>
                <li><b>EXPLAIN [EXTENDED]</b> in SQL</li>
              </ul>
            </li>
            <li><b>Logical Query Plan Analyzer</b> is a RuleExecutor with rules to optimize query execution</li>
            <li>Switch to Mastering Apache Spark 2
              <ul>
                <li><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/spark-sql-dataset-operators.html#explain">Explaining Logical and Physical Plans &mdash; explain Operator</a></li>
                <li><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-sql-Analyzer.html">Analyzer &mdash; Logical Query Plan Analyzer</a></li>
              </ul>
            </li>
          </ol>
        </section>

        <section id="recap" data-markdown>
          <script type="text/template">
            ## Recap

            1. [Multi-dimensional rollup Operator](#/rollup)
              * [Exercise](#/rollup-exercise): Total and average salaries by department and company-wide
            1. [Multi-dimensional cube Operator](#/cube)
            1. [GROUPING SETS SQL clause](#/grouping-sets)
            1. [grouping Aggregate Function](#/grouping)
            1. [grouping_id Aggregate Function](#/grouping-id)
              * [Exercise](#/grouping-id-exercise): Convert grouping_id to bitmask
            1. ["Explaining" Query Plans](#/explain)
          </script>
        </section>

        <section id="questions" style="text-align: left">
          <h1>Questions?</h1>
          <p>
            <ul>
              <li>Read <a href="https://bit.ly/mastering-apache-spark">Mastering Apache Spark 2</a>
                <ul>
                  <li><a href="https://bit.ly/mastering-apache-spark">https://bit.ly/mastering-apache-spark</a></li>
                </ul>
              </li>
              <li>Follow <a href="https://twitter.com/jaceklaskowski">@jaceklaskowski</a> on twitter</li>
              <li>Upvote <a href="http://stackoverflow.com/users/1305344/jacek-laskowski">my questions and answers on StackOverflow</a></li>
              <li>Use <a href="https://github.com/jaceklaskowski">Jacek's code at GitHub</a></li>
              <li>Read <a href="https://medium.com/@jaceklaskowski">my blog posts on Medium</a></li>
              <li>Upvote <a href="https://www.quora.com/profile/Jacek-Laskowski">my answers on Quora</a></li>
              <li>Connect on <a href="https://www.linkedin.com/in/jaceklaskowski/">LinkedIn</a></li>
              <li>Visit <a href="https://blog.jaceklaskowski.pl">Jacek Laskowski's blog</a></li>
            </ul>
          </p>
        </section>

      </div>
    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>

    <script>
        // More info https://github.com/hakimel/reveal.js#configuration
        Reveal.initialize({
        history: true,

        transition: 'slide', // none/fade/slide/convex/concave/zoom

        // More info https://github.com/hakimel/reveal.js#dependencies
        dependencies: [
          { src: 'plugin/markdown/marked.js' },
          { src: 'plugin/markdown/markdown.js' },
          { src: 'plugin/notes/notes.js', async: true },
          { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
        ]
        });
		</script>

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-45999426-3', 'auto');
      ga('send', 'pageview');

    </script>
  </body>
</html>
