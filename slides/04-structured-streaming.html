<!doctype html>
<!-- Inspired by view-source:https://brookewenig.github.io/SparkOverview.html  -->
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <meta name="description" content="Apache Spark 2 Workshop | Structured Streaming">
    <meta name="author" content="Jacek Laskowski">

    <title>Apache Spark 2 Workshop | Structured Streaming</title>

    <link rel="stylesheet" href="reveal.js/css/reveal.css">
    <link rel="stylesheet" href="reveal.js/css/jacek.css">
		<link rel="stylesheet" href="reveal.js/css/theme/beige.css">

    <!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">

    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

    <!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
  </head>

  <body>
    <div class="reveal">
      <div class="slides">

        <section class="intro" data-transition="zoom" id="home">
          <span class="menu-title" style="display: none">Home</span>
          <p>
            <img width="5%" style="background:none; border:none; box-shadow:none;" data-src="images/scala-logo.png">
            <img width="17%" style="background:none; border:none; box-shadow:none;" data-src="images/spark-logo.png">
            <img width="8%" src="images/jacek_laskowski_20141201_512px.png" style="border: 0">
          </p>
          <h1 style="font-size: 3.55em;">Structured Streaming</h1>
          <h1 style="font-size: 2.77em;">Apache Spark 2.2</h1>

          <h4><a href="https://twitter.com/jaceklaskowski">@jaceklaskowski</a> / <a href="http://stackoverflow.com/users/1305344/jacek-laskowski">StackOverflow</a> / <a href="https://github.com/jaceklaskowski">GitHub</a><br />
          Books: <a href="http://bit.ly/mastering-apache-spark">Mastering Apache Spark</a>  / <a href="http://bit.ly/spark-structured-streaming">Spark Structured Streaming</a></h4>

          <footer style="font-size: small;">&copy;<a href="https://medium.com/@jaceklaskowski">Jacek Laskowski</a> 2017 / @jaceklaskowski / jacek@japila.pl</footer>
        </section>

        <section id="agenda" data-markdown>
          <script type="text/template">
            ## Agenda

            1. [Structured Streaming](#/intro)
            1. [DataStreamReader](#/datastreamreader)
            1. [DataStreamWriter](#/datastreamwriter)
            1. [Streaming Source](#/streaming-source)
            1. [Streaming Sink](#/streaming-sink)
            1. [Streaming Query](#/streaming-query)
            1. [StreamingQueryManager](#/streaming-query-manager)
            1. [Demo: Streaming with Rate Source](#/demo-rate)
            1. [Exercises](#/exercises)
          </script>
        </section>

        <section id="intro">
          <h2>Structured Streaming</h2>
          <ol>
            <li><b>Structured Streaming</b> is a new computation model in Spark 2 that is an attempt to unify streaming, interactive, and batch query execution engines</li>
            <li>Switch to Mastering Apache Spark 2
              <ul>
                <li><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-structured-streaming.html">Spark Structured Streaming &mdash; Streaming Datasets</a></li>
              </ul>
            </li>
          </ol>
        </section>

        <section id="datastreamreader">
          <h2>DataStreamReader</h2>
          <ol>
            <li><b>DataStreamReader</b> is an interface for executing structured queries periodically (giving you nearly-streaming processing)
              <pre><code>
       val streamReader: DataStreamReader = spark.readStream
              </code></pre>
            </li>
            <li>Structured query is described as a streaming Dataset (and DataFrame)</li>
            <li>Switch to Spark Structured Streaming
              <ul>
                <li><a href="https://jaceklaskowski.gitbooks.io/spark-structured-streaming/content/spark-sql-streaming-DataStreamReader.html">DataStreamReader</a></li>
              </ul>
            </li>
          </ol>
        </section>

        <section id="datastreamwriter">
          <h2>DataStreamWriter</h2>
          <ol>
            <li><b>DataStreamWriter</b> is the interface for writing result of structured queries
              <pre><code>
     val streamWriter: DataStreamWriter = dataset.writeStream
              </code></pre>
            </li>
            <li>Switch to Spark Structured Streaming
              <ul>
                <li><a href="https://jaceklaskowski.gitbooks.io/spark-structured-streaming/content/spark-sql-streaming-DataStreamWriter.html">DataStreamWriter</a></li>
              </ul>
            </li>
          </ol>
        </section>

        <section id="streaming-source">
          <h2>Streaming Source</h2>
          <ol>
            <li><b>Streaming Source</b> represents a continuous stream of data for a streaming query.</li>
            <li>Defined using <b>format</b> method on <b>DataFrameReader</b></li>
            <li><b>FileStreamSource</b> and <b>TextSocketSource</b> for files
            <li><b>KafkaSource</b> for Apache Kafka 0.10.x</li>
            <li><b>RateStreamSource</b> and <b>MemoryStream</b> for unit tests, PoCs, tutorials and debugging</li>
            <li>Switch to Spark Structured Streaming
              <ul>
                <li><a href="https://jaceklaskowski.gitbooks.io/spark-structured-streaming/content/spark-sql-streaming-Source.html">Streaming Source</a></li>
              </ul>
            </li>
          </ol>
        </section>

        <section id="streaming-sink">
          <h2>Streaming Sink</h2>
          <ol>
            <li><b>Streaming Sink</b> represents an external storage to write streaming datasets to.</li>
            <li>Defined using <b>format</b> method on <b>DataFrameWriter</b></li>
            <li><b>ConsoleSink</b>, <b>FileStreamSink</b> and <b>ForeachSink</b></li>
            <li><b>KafkaSink</b> for Apache Kafka 0.10.x</li>
            <li><b>MemorySink</b> for unit tests, tutorials and debugging</li>
            <li>Switch to Spark Structured Streaming
              <ul>
                <li><a href="https://jaceklaskowski.gitbooks.io/spark-structured-streaming/content/spark-sql-streaming-Sink.html">Streaming Sink</a></li>
              </ul>
            </li>
          </ol>
        </section>

        <section id="streaming-query">
          <h2>StreamingQuery</h2>
          <ol>
            <li><b>StreamingQuery</b> represents a streaming structured query
              <pre><code>
     val query: StreamingQuery = counter.writeStream.start
              </code></pre>
            </li>
            <li>Switch to Spark Structured Streaming
              <ul>
                <li><a href="https://jaceklaskowski.gitbooks.io/spark-structured-streaming/content/spark-sql-streaming-StreamingQuery.html">StreamingQuery</a></li>
              </ul>
            </li>
          </ol>
        </section>

        <section id="streaming-query-manager">
          <h2>StreamingQueryManager — Streaming Query Management</h2>
          <ol>
            <li><b>StreamingQueryManager</b> is the Management API for continuous queries per SparkSession
              <pre><code>
          val qm: StreamingQueryManager = spark.streams
              </code></pre>
            </li>
            <li>Switch to Spark Structured Streaming
              <ul>
                <li><a href="https://jaceklaskowski.gitbooks.io/spark-structured-streaming/content/spark-sql-streaming-StreamingQueryManager.html">StreamingQueryManager &mdash; Streaming Query Management</a></li>
              </ul>
            </li>
          </ol>
        </section>

        <section id="demo-rate" data-markdown>
          <script type="text/template">
            ## Streaming with Rate Source
            ### (Demo)

            1. Simple rate-to-console pipeline
            1. Using **rate** format for source and **console** for sink
          </script>
        </section>

        <section>
          <section id="exercises">
            <div style="text-align: left">
    					<h2>Exercises</h2>
              <hr>
    					<p><i class="fa fa-arrow-circle-right success"></i>&nbsp;
                <a href="#/exercise-csv">Streaming CSV Files</a>
              </p>
    					<p><i class="fa fa-arrow-circle-right success"></i>&nbsp;
                <a href="#/exercise-kafka">From and To Apache Kafka</a>
              </p>
    					<p><i class="fa fa-arrow-circle-right success"></i>&nbsp;
                <a href="#/exercise-groupBy">Streaming Aggregation with groupBy</a>
              </p>
            </div>
            <footer style="font-size: small;">&copy;Jacek Laskowski 2017 / @jaceklaskowski / jacek@japila.pl</footer>
          </section>
          <section id="exercise-csv" data-markdown>
            <script type="text/template">
              ## Streaming CSV Files

              1. Develop a standalone Spark SQL application
                * Use IntelliJ IDEA
              1. Use **csv** format for source and **console** for sink
              1. Use **sbt package** and **spark-submit**
              1. Time: **30 mins**
            </script>
          </section>
          <section id="exercise-kafka" data-markdown>
            <script type="text/template">
              ## From and To Apache Kafka

              1. Start Kafka Broker and Console Producer
              1. Develop a standalone Spark SQL application
                * Use IntelliJ IDEA
              1. (part 1) **kafka** format for source and **console** for sink
              1. (part 2) **kafka** format for source and **kafka** for sink
              1. Use **sbt package** and **spark-submit**
              1. Read [KafkaSource](https://jaceklaskowski.gitbooks.io/spark-structured-streaming/content/spark-sql-streaming-KafkaSource.html)
              1. Time: **45 mins**
            </script>
          </section>
          <section id="exercise-groupBy" data-markdown>
            <script type="text/template">
              ## Streaming Aggregation with groupBy

              1. Develop a standalone Spark SQL application
                * Use IntelliJ IDEA
              1. Read datasets from Apache Kafka (**kafka** source)
              1. Use **groupBy** operator on streaming Dataset
              1. Use **sbt package** and **spark-submit**
              1. Time: **45 mins**
            </script>
          </section>
        </section>

        <section>
          <section id="structured-streaming-internals">
            <div style="text-align: left">
    					<h2>Internals / StreamExecution <small>(1 of 4)</small></h2>
              <hr>
    					<p><i class="fa fa-arrow-circle-right success"></i>&nbsp;
                <b>StreamExecution</b> &mdash; execution environment of a single continuous query (aka <b>streaming Dataset</b>)</p>
              <p><i class="fa fa-arrow-circle-right success"></i>&nbsp;
                StreamExecution has multiple streaming <b>sources</b> but only one streaming <b>sink</b></p>
    					<p><i class="fa fa-arrow-circle-right success"></i>&nbsp;
                Executes every <b>trigger</b> and adds results to the <b>sink</b></p>
    					<p><i class="fa fa-arrow-circle-right success"></i>&nbsp;
                Created exclusively when <b>DataStreamWriter</b> is started.</p>
            </div>
            <footer style="font-size: small;">&copy;Jacek Laskowski 2017 / @jaceklaskowski / jacek@japila.pl</footer>
          </section>
          <section>
            <div style="text-align: left">
    					<h2>StreamExecution <small>(2 of 4)</small></h2>
              <hr>
              <div style="text-align: left">
                <p><i class="fa fa-arrow-circle-right success"></i>&nbsp;
                  StreamExecution starts a <b>thread of execution</b> that runs the streaming query continuously and concurrently</p>
              </div>
              <div style="text-align: center">
							  <img src="https://jaceklaskowski.gitbooks.io/spark-structured-streaming/images/StreamExecution-start.png">
              </div>
            </div>
            <footer style="font-size: small;">&copy;Jacek Laskowski 2017 / @jaceklaskowski / jacek@japila.pl</footer>
          </section>
          <section>
            <div style="text-align: left">
    					<h2>StreamExecution <small>(3 of 4)</small></h2>
              <hr>
              <div style="text-align: center">
							  <img src="https://jaceklaskowski.gitbooks.io/spark-structured-streaming/images/StreamExecution-uniqueSources.png">
              </div>
            </div>
            <footer style="font-size: small;">&copy;Jacek Laskowski 2017 / @jaceklaskowski / jacek@japila.pl</footer>
          </section>
          <section>
            <div style="text-align: left">
    					<h2>StreamExecution <small>(4 of 4)</small></h2>
              <hr>
              <div style="text-align: left">
                <p><i class="fa fa-arrow-circle-right success"></i>&nbsp;
                  StreamExecution collects <b>duration</b> for the execution units of a streaming batch</p>
                <p><i class="fa fa-arrow-circle-right success"></i>&nbsp;
                  Use <b>StreamingQuery.lastProgress</b> or <b>StreamingQuery.recentProgress</b></p>
              </div>
              <div style="text-align: center">
							  <img src="https://jaceklaskowski.gitbooks.io/spark-structured-streaming/images/StreamExecution-durationMs.png">
              </div>
            </div>
            <footer style="font-size: small;">&copy;Jacek Laskowski 2017 / @jaceklaskowski / jacek@japila.pl</footer>
          </section>
				</section>

        <section>
          <section>
            <div style="text-align: left">
    					<h2>Internals / IncrementalExecution</h2>
              <hr>
    					<p><i class="fa fa-arrow-circle-right success"></i>&nbsp;
                <b>IncrementalExecution</b> &mdash; QueryExecution of a streaming Dataset</p>
    					<p><i class="fa fa-arrow-circle-right success"></i>&nbsp;
                Created (in <b>queryPlanning</b> Phase) for incremental execution of the logical query plan (every trigger)</p>
            </div>
            <footer style="font-size: small;">&copy;Jacek Laskowski 2017 / @jaceklaskowski / jacek@japila.pl</footer>
          </section>
				</section>

        <section id="recap" data-markdown>
          <script type="text/template">
            ## Recap

            1. [Structured Streaming](#/intro)
            1. [DataStreamReader](#/datastreamreader)
            1. [DataStreamWriter](#/datastreamwriter)
            1. [Streaming Source](#/streaming-source)
            1. [Streaming Sink](#/streaming-sink)
            1. [Streaming Query](#/streaming-query)
            1. [StreamingQueryManager](#/streaming-query-manager)
            1. [Demo: Streaming with Rate Source](#/demo-rate)
            1. [Exercises](#/exercises)
          </script>
        </section>

        <section style="text-align: left" data-markdown id="questions">
          <script type="text/template">
            # Questions?

            * Read [Mastering Apache Spark 2](https://bit.ly/mastering-apache-spark)
              * [https://bit.ly/mastering-apache-spark](https://bit.ly/mastering-apache-spark)
            * Follow [@jaceklaskowski](https://twitter.com/jaceklaskowski) on twitter
            * Upvote [my questions and answers on StackOverflow](http://stackoverflow.com/users/1305344/jacek-laskowski)
          </script>
        </section>

      </div>
    </div>

    <script src="reveal.js/lib/js/head.min.js"></script>
		<script src="reveal.js/js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
        controls: true,
				progress: true,
				history: true,
				center: true,
				slideNumber: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				menu: {
					markers: true,
					openSlideNumber: true
				},
        dependencies: [
          { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'reveal.js/plugin/markdown/marked.js' },
					{ src: 'reveal.js/plugin/markdown/markdown.js' },
          { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
					{ src: 'reveal.js/plugin/notes/notes.js', async: true },
          { src: 'reveal.js/plugin/menu/menu.js', async: true },
					{ src: 'reveal.js/plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
